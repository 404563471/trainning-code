---
title: "Multivariate-Statistical"
author: "mason-YHY"
date: "6/16/2020"
output: html_document
---

Generalized Linear Models
=====================================================
```{r}
library(MASS)
library(mlbench)
data(PimaIndiansDiabetes)
head(PimaIndiansDiabetes)
diabetes <- as.data.frame(scale(PimaIndiansDiabetes[1:8]))
diabetes.lmfit <- glm(glucose~., family=gaussian, data=diabetes)
summary(diabetes.lmfit)
step.lmfit <- step(diabetes.lmfit)
summary(step.lmfit)
```

logistic---0,1 分类
======================================================
Example 1
```{r}
library(DAAG)
data("anesthetic")
head(anesthetic)
cdplot(factor(nomove)~conc,data=anesthetic,main='条件密度图',ylab='病人移动',xlab='麻醉剂量')

anes1 <- glm(nomove~conc,data=anesthetic,family=binomial(link='logit'))

summary(anes1)

anestot <- aggregate(anesthetic[,c('move','nomove')],by=list(conc=anesthetic$conc),FUN=sum)
anestot$conc <- as.numeric(as.character(anestot$conc))
anestot$total <- apply(anestot[,c('move','nomove')],1,sum)
anestot$prop <- anestot$nomove/anestot$total
anestot

anes2 <- glm(cbind(nomove,move)~conc,data=anestot,family=binomial(link='logit'))
#anes2=glm(cbind(move,nomove)~conc,family=binomial(link='logit'),data=anestot)
summary(anes2)
anes3 <- glm(prop~conc,data=anestot,family=binomial(link='logit'),weights=total)
summary(anes3)

x <- seq(from=0,to=3,length.out=30)
y <- predict(anes1,data.frame(conc=x),type='response')
plot(prop~conc,pch=16,col='red',data=anestot,xlim=c(0.5,3),main='Logistic回归曲线图',ylab='病人静止概率',xlab='麻醉剂量')
lines(y~x,lty=2,col='blue')
```
Example 2

- OR = 1: No effect
- OR < 1: Reduction in the hazard
- OR > 1: Increase in Hazard
```{r}
cancerdata <- data.frame(smoke=factor(rep(c(0,1),c(199+170,101+416))),
                         drink=factor(rep(c(0,1,0,1),c(199,170,101,416))),
                         Y=factor(rep(c(0,1,0,1,0,1,0,1),c(136,63,107,63,57,44,151,265))))

cancerdata.fit <- glm(Y~., data = cancerdata, family = binomial(link = 'logit'))
summary(cancerdata.fit)
# OR
exp(coef(cancerdata.fit))
exp(confint(cancerdata.fit))
```

1. 模型构建
```{r}
diabetes$diabetes <- factor(PimaIndiansDiabetes$diabetes, levels = c("neg", "pos"), labels = c(0, 1))
head(diabetes)

diabetes.logitfit <- glm(diabetes~. , data = diabetes,family=binomial(link='logit'))
summary(diabetes.logitfit)
step.logitfit <- step(diabetes.logitfit)
summary(step.logitfit)
```
2. 预测分类
```{r}
diabetesValue <- data.frame(diabetes=diabetes$diabetes, values=step.logitfit$fitted.values)
hist(subset(diabetesValue, diabetes==0)$values, breaks = 20, col = rgb(0,0,1,0.5), main = "Look for Cutoff", xlab = "neg and pos")
hist(subset(diabetesValue, diabetes==1)$values, breaks = 20, col = rgb(1,0,0,0.5), add=TRUE)
diabetesValue$predict <- ifelse(diabetesValue$values>=0.5, 1, 0)

predictTable <- table(diabetesValue[, c("diabetes", "predict")])
predictTable
prop.table(predictTable)
```
3. ROC 曲线评价模型
```{r}
library(pROC)
modelroc <- roc(diabetes~values, data = diabetesValue)
par(pty = "s")
plot(modelroc, legacy.axes=TRUE, print.auc=TRUE, print.thres=TRUE, auc.polygon=TRUE)
```
4. Conditional logistic regression
```{r}
library(survival)
data(infert)
infert.fit1 <- clogit(case ~ factor(spontaneous)+factor(induced)+strata(stratum), data = infert)
summary(infert.fit1)
infert.fit2 <- glm(case ~ factor(spontaneous)+factor(induced), data = infert, family = binomial(link='logit'))
#summary(infert.fit2)
```
5. ROC 曲线compare
```{r}
fit1.roc <- roc(infert$case, predict(infert.fit1))
fit2.roc <- roc(infert$case, predict(infert.fit2))
roc.test(fit1.roc, fit2.roc)

par(pty = "s")
plot(fit1.roc, legacy.axes=TRUE, col="red")
plot(fit2.roc, legacy.axes=TRUE, col="blue", add=TRUE)
```


lDA线性判别
=========================================================
```{r}
library(MASS)
ld <- lda(Species~. , data = iris)
ld
plot(ld)

rawG <- iris$Species
ldPre <- predict(ld)
ldG <- ldPre$class
tab1 <- table(rawG, ldG)
tab1
sum(diag(prop.table(tab1)))

plot(ldPre$x, col=iris$Species)
points(ldPre$x[!(ldPre$class==iris$Species),], pch=8)
```

QDA二次判别
========================================================
```{r}
qd <- qda(Species~. , data = iris)
qd
qdPre <- predict(qd)
qdG <- qdPre$class
tab2 <- table(rawG, qdG)
tab2
sum(diag(prop.table(tab2)))
```

Bayes先验概率
=======================================================
```{r}
bayes <- lda(Species~. , data = iris, prior=c(1,2,3)/6)
bayes
bayesPre <- predict(bayes)
ldG2 <- bayesPre$class
tab3 <- table(rawG, ldG2)
tab3
sum(diag(prop.table(tab3)))
```

Cox proportional hazards model---连续伴有删失
========================================================

- HR = 1: No effect
- HR < 1: Reduction in the hazard
- HR > 1: Increase in Hazard

1. 单因素cox
```{r}
library("survival")
library("survminer")

data("lung")
head(lung)
res.cox <- coxph(Surv(time, status) ~ sex, data = lung)
res.cox
summary(res.cox)
```

2. 多因素cox
```{r}
res.cox <- coxph(Surv(time, status) ~ age + sex + ph.ecog, data = lung)
summary(res.cox)
```

3. Flexible parametric regression
```{r}
library(flexsurv)

# built-in distribution
flexsurvreg(Surv(time, status) ~ age + sex + ph.ecog, data = lung, dist = "gompertz")
flexsurvreg(Surv(time, status) ~ age + sex + ph.ecog, data = lung, dist = "gamma")
```


层次聚类HCluster
===========================================
1. 开始时，将每个样本作为一类。
2. 规定某种度量作为样本之间距离以及类距离之间的度量，并且计算之。（hculster里边的dist方法以及method属性）
3. 将距离最短的两个类合并为一个类。
4. 重复2-3，即不断合并最近的两个类，每次减少一个类，直到所有的样本合并为一个类。

```{r}
iris2 <- iris[, 1:4]
euclideanDist <- dist(iris2, method = "euclidean")
#euclideanDist
hc <- hclust(euclideanDist, method = "ave")  #注意hcluster里边传入的是dist返回值对象

plot(hc, hang=-1,labels=iris$Species, cex=0.5)  #这里的hang=-1使得树的节点在下方对齐
#将树分为3块
rect.hclust(hc,k=3)  

#
groups <- cutree(hc,k=3)
groups
```

```{r}
par(mfrow = c(6,1), mai=c(0.1, 0.1, 0.1, 0.1))

Methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
for (distMethod in Methods) {
  irisDist <- dist(iris2, method = distMethod)
  irisHc <- hclust(irisDist, method = "ave")
  plot(irisHc, hang=-1, main = NULL, sub = NULL, ylab = NULL, ann = FALSE ,labels = FALSE, axes = FALSE)  
  rect.hclust(irisHc, k=3) 
} 
```

```{r}
par(mfrow = c(8,1), mai=c(0.1, 0.1, 0.1, 0.1))

Methods <- c( "average", "complete", "median", "ward.D", "ward.D2", "single", "mcquitty", "centroid")
for (hcMethod in Methods) {
  irisDist <- dist(iris2, method = "euclidean")
  irisHc <- hclust(irisDist, method = hcMethod)
  plot(irisHc, hang=-1, main = NULL, sub = NULL, ylab = NULL, ann = FALSE ,labels = FALSE, axes = FALSE)  
  rect.hclust(irisHc, k=3) 
} 
```

快速聚类--kmeans
==========================================================
```{r}
set.seed(100)
x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
           matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))

colnames(x) <- c("x", "y")
cl <- kmeans(x, 2)

plot(x, col = cl$cluster)
points(cl$centers, col = 1:2, pch = 8, cex = 2)
```

kmeans分析iris
```{r}
set.seed(100)
iris3<-iris[, 1:4] + rchisq(150, 2)
iris.kmeans<-kmeans(iris3, 3)
iris.kmeans

origin_group <- as.character(factor(iris$Species, labels = c("black", "red", "green")))
plot(iris3, col=origin_group)

plot(iris3, col=iris.kmeans$cluster)
```

K-mediods算法
=================================================
```{r}
library(cluster)
iris.pam <- pam(iris3, 3)
pam_group <- iris.pam$clustering
#pam_group <- c(2, 3, 1)[pam_group]
plot(iris3, col=pam_group)

iris.pam
```


DBSCAN（基于密度的聚类算法）
========================================================
r-邻域：给定点半径为r的区域。
核心点：如果一个点的r邻域内最少包含M个点，则该点称为核心点。
直接密度可达：对于核心点P而言，如果另一个点O在P的r邻域内，那么称O为P的直接密度可达点。
密度可达：对于P的直接密度可达点O的r邻域内，如果包含另一个点Q，那么称Q为P的密度可达点。
密度相连：如果Q和N都是核心点P的密度可达点，但是并不在一条直线路径上，那么称两者为密度相连。

指定R和M，计算所有的样本点，如果点p的r邻域内有超过M个点，那么创建一个以P为核心点的新簇，反复寻找这些核心点的直接密度可达点（之后可能是密度可达），将其加入到相应的簇，对于核心点发生密度相连的情况加以合并，当没有新的点加入到任何簇中时，算法结束。

优点：
（1）聚类速度快且能够有效处理噪声点和发现任意形状的空间聚类；
（2）与K-MEANS比较起来，不需要输入要划分的聚类个数；
（3）聚类簇的形状没有偏倚；
（4）可以在需要时输入过滤噪声的参数。

缺点：
（1）当数据量增大时，要求较大的内存支持I/O消耗也很大；
（2）当空间聚类的密度不均匀、聚类间距差相差很大时，聚类质量较差，因为这种情况下参数MinPts和Eps选取困难
（3）算法聚类效果依赖与距离公式选取，实际应用中常用欧式距离，对于高维数据，存在“维数灾难”。
```{r}
library(fpc)
iris.dbscan <- dbscan(iris3, 0.4, MinPts = 2, scale = TRUE)
plot(iris.dbscan, iris3)

library(mlbench)
spirals_data <- mlbench.spirals(1000, 3)
plot(spirals_data)

cluster_data <- spirals_data$x
k_cluster <- kmeans(cluster_data, 2)
plot(cluster_data, col=k_cluster$cluster)
points(k_cluster$cluster, pch = 8, cex=1.5, col="green")

#for (i in seq(0.1, 1, 0.1)) {
dbscan_cluster <- dbscan(cluster_data, 0.1, MinPts = 2)
plot(dbscan_cluster, cluster_data)
#}
```


PCA (Principal Components Analysis) 主成分分析
===========================================================
```{r}
#cor是逻辑变量,当cor=TRUE表示用样本的相关矩阵R做主成分分析,当cor=FALSE表示用样本的协方差阵S做主成分分
pcaX <- princomp(iris2, cor=FALSE)
pcaX
summary(pcaX)
screeplot(pcaX, type='lines')
pcaX$loadings

plot(pcaX$scores[,1:2], type = 'n', asp = 1)
text(pcaX$scores[,1:2], labels = iris$Species, cex = 0.6)
```

EFA-----因子分析
===========================================================
```{r}
v1 <- c(1,1,1,1,1,1,1,1,1,1,3,3,3,3,3,4,5,6)
v2 <- c(1,2,1,1,1,1,2,1,2,1,3,4,3,3,3,4,6,5)
v3 <- c(3,3,3,3,3,1,1,1,1,1,1,1,1,1,1,5,4,6)
v4 <- c(3,3,4,3,3,1,1,2,1,1,1,1,2,1,1,5,6,4)
v5 <- c(1,1,1,1,1,3,3,3,3,3,1,1,1,1,1,6,4,5)
v6 <- c(1,1,1,2,1,3,3,3,4,3,1,1,1,2,1,6,5,4)
m1 <- cbind(v1,v2,v3,v4,v5,v6)
cor(m1)
## rotate：旋转方法，默认为变异数最小法；"varimax"正交旋转将人为地强制3个因子不相关，"promax"斜交旋转允许3个因子相关。
factanal(m1, factors = 3) # varimax is the default
factanal(m1, factors = 3, rotation = "promax")

pca <- princomp(diabetes[,1:8])
summary(pca)
pca$loadings

fac <- factanal(diabetes[,1:8], factors = 4)
fac
```


MDS-----Multidimensional Scaling 多维度数据缩放
========================================================
度量法，经典解，相似性数据是用距离尺度或比率尺度测得的
```{r}
# X 的k维主坐标是将X 中心化后n个样本的前k个主成分的值
mdsDist <- dist(iris[,1:4])
mds1 <- cmdscale(mdsDist)
head(mds1)
plot(mds1[,1], mds1[,2], type = 'n', asp = 1)
text(mds1[,1], mds1[,2], labels = iris$Species, cex = 0.6)
```

非度量法， 若模型需要顺序量表水平的相似数据，就称为非度量化模型
```{r}
library(MASS)
# 在iris中存在重复值，会导致距离矩阵出现0
mdsDist <- dist(unique(iris[,1:4]))
mds2 <- isoMDS(mdsDist)

head(mds2$points)
#stress (in percent) 为压力值，为k的单调递减函数，通过调节k使stress减小，小于5%为最佳，大于10%为差
mds2$stress
mds2x <- mds2$points[,1]
mds2y <- mds2$points[,2]

plot(mds2x, mds2y, type = 'n', asp = 1)
text(mds2x, mds2y, labels = iris$Species, cex = 0.6)
```

对应分析
=======================================================
```{r}
library(ca)
data("author")
caFit <- ca(author)
plot(caFit)
```

Canonical Correlations---经典相关分析
======================================================
```{r}
sepal <- iris[, c("Sepal.Length", "Sepal.Width")]
petal <- iris[, c("Petal.Length", "Petal.Width")]
cancor(sepal, petal)
```
